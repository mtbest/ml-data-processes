---
title: "ML Data Analysis Code"
output: html_notebook
---
# ML Data Analysis Code

## Intro

This is the R Notebook for our ML Data Analysis Code. We originally worked on this in an RScript, but will now use an R Notebook for it. The data used in this file will come from a simulated dataset.

## Download packages

``` {r include = FALSE}
library(tidyverse) # for data management
library(psych) # to analyze data and descriptive statistics
library(ggplot2) # to make some nice graphs
library(pander) # to make some clean tables
library(here) # to make it easier to grab files from the folder where this one sits

```

## Load in RScript where functions are created

We don't have an RScript with functions yet

``` {r include = TRUE}

#source(__.R)

```

## Download Simulated Data

``` {r include = TRUE}

source(here(simulate-data.R))

```


## Data Analysis

### ANOVAs with Tukey HSD post-hocs

``` {r include = TRUE}

dv_gv_AOV <- aov(lm(dv ~ as.factor(gv), data = d)) # dv is the dependent variable
pander(summary(dv_gv_AOV))                         # and gv is the group variable
TukeyHSD(dv_gv_AOV)

pander(summarySE(d, groupvar="gv", measurevar="dv",na.rm=TRUE),round=2)

```


### Factorial ANOVAs with other post-hoc corrections

``` {r include = TRUE}



```


### Correlation matrix

``` {r include = TRUE}

# Creating a function to create nice correlation matrices

cortable <- function(x){ 
  require(Hmisc) 
  x <- as.matrix(x) 
  R <- rcorr(x)$r 
  p <- rcorr(x)$P 
  ## define notions for significance levels; spacing is important.
  mystars <- ifelse(p < .001, "***", ifelse(p < .01, "** ", ifelse(p < .05, "* ", " ")))
  ## truncate the matrix that holds the correlations to two decimal
  R <- format(round(cbind(rep(-1.11, ncol(x)), R), 2))[,-1] 
  ## build a new matrix that includes the correlations with their appropriate stars 
  Rnew <- matrix(paste(R, mystars, sep=""), ncol=ncol(x)) 
  diag(Rnew) <- paste(diag(R), " ", sep="") 
  rownames(Rnew) <- colnames(x) 
  colnames(Rnew) <- paste(colnames(x), "", sep="") 
  ## remove upper triangle
  Rnew <- as.matrix(Rnew)
  Rnew[upper.tri(Rnew, diag = TRUE)] <- ""
  Rnew <- as.data.frame(Rnew) 
  ## remove last column and return the matrix (which is now a data frame)
  Rnew <- cbind(Rnew[1:length(Rnew)-1])
  return(Rnew) 
} 

# Example code for a correlation matrix

ex_corr <- cortable(d[c("v1", "v2", "v3", "v4", "v5", "v6")])

pander(ex_corr,round=2,title = "Item Correlations")

```


### Creating great tables and graphs

``` {r include = TRUE}

```


### EFA

``` {r include = TRUE}

d$scale <- d[c("v1", "v2", "v3", "v4", "v5", "v6")]
pander(fa.parallel(d$scale))

```


### CFA

``` {r include = TRUE}

CFA_mod1 <- 
  'F1 = ~ v1 + v2 + v3 + v4
   F2 = ~ v5 + v6'

CFA1 <- cfa(model = CFA_mod1, data = d)

pander(summary(CFA1, fit.measures = TRUE, standardized = TRUE))
pander(inspect(CFA1, "std")$lambda)

pander(fitMeasures(CFA1, fit.measures = c("cfi", "tli", "rmsea")))
pander(standardizedSolution(CFA1) %>%
         filter(op == "=~" & lhs == "F2"))

semPaths(CFA1)

```


### Path analysis and SEM

``` {r include = TRUE}

```


### Reliability / Cronbach's alpha coefficients

``` {r include = TRUE}

d$scale <- d[c("v1", "v2", "v3", "v4", "v5", "v6")]
scale_alpha <- alpha(d$scale)
pander(scale_alpha$total)
pander(cortable(d$scale)) # uses correlation matrix function from above to look at
                          # inter-item correlations

```


### Linear regression

``` {r include = TRUE}

lm(y ~ x, data = data) # very basic linear regression equation
ggplot(data, aes(x, y)) +
  geom_point() + geom_smooth(method = "lm", se = 0)

lm(y ~ x + factor(z) + x:factor(z), data = data) # interaction linear regression equation
ggplot(data, aes(x, y, color = factor(z))) +
  geom_point() + geom_smooth(method = "lm", se = 0)

```


### Logistic regression

``` {r include = TRUE}

glm(y ~ x, data, family = 'binomial') # very basic logistic regression equation

```


### Tests of baseline equivalence

``` {r include = TRUE}

```


### Multilevel models / HLMs

Given these models need context, I am inserting code below from an analysis we ran on our MAP USSF Development Academy data predicting Goals Scored for Attacking Players. We wanted to look at the random effect of club on the outcome of goals scored in tandem with growth mindset variables and demographic variables.

``` {r include = TRUE}

mod1 <- lmer(Goals ~ (1|Club),data=Attacking) # Goals is DV and Club as a random intercept
mod2 <- lmer(Goals ~ PGM_S + CGM_S + PGM_S:CGM_S + (1|Club),data=Attacking) # Goals is DV, 
                                                                    # Player and Coach
                                                                    # GM interaction,
                                                                    # Club as random intercept
mod3 <- lmer(Goals ~ AgeGroup_fac + urm + (1|Club),data=Attacking) # Goals is DV, 
                                                          # Age Group and Ethnicity
                                                          # analyzed as demographics,
                                                          # Club as random intercept
mod4 <- lmer(Goals ~ PGM_S + CGM_S + PGM_S:CGM_S + AgeGroup_fac + urm + (1|Club), data=Attacking)
    # Combined model: Goals is DV, Player and Coach GM interaction, Age Group and Ethnicity
    # included, Club as random intercept

htmlreg(list(mod1,mod2,mod3,mod4),
        
        # this adds a symbol for marginal significance
        stars= c(0.001, 0.01, 0.05, 0.1),
        custom.coef.names = c("Intercept","Player GM (z)", "Coach GM (z)", 
                              "Player-Coach GM Interaction", "U-14","U-15","U-16/17",
                              "U-18/19","URM"),
        custom.model.names = c("Base Model","Growth Mindset","Demographics","Both"),
        caption="Growth Mindset Predicting Goals Scored for Attackers")


```


### Response surface analysis

``` {r include = TRUE}


```


### Cluster analysis

``` {r include = TRUE}

```


### Multigroup analysis (testing indirect effects in a path model for different demographic groups)

``` {r include = TRUE}

```


### Profile analysis

``` {r include = TRUE}

```


### Power analysis

``` {r include = TRUE}

```


### Bayesian predictive models

``` {r include = TRUE}

```


### Mediation/moderation analysis

``` {r include = TRUE}

```


### Propensity score matching

``` {r include = TRUE}

# propensity score matching
set.seed(123)

library(MatchIt)
library(lmtest)
library(sandwich)

match_obj <- d_post %>% # for the purpose of the exercise, we'll imagine whether they took a math class as the intervention
  filter(!is.na(Dt2_gpa)) %>%
  matchit(Dt2_math ~ Rt2_per_income + Dt2_race_ML + St2_sp_bel_bu1,
                     data = ., method = "nearest", distance = "glm",
                     ratio = 1,
                     replace = FALSE,
                     exact = ~ Rt2_per_income + Dt2_race_ML)
summary(match_obj)

plot(match_obj, type = "jitter", interactive = FALSE)
plot(summary(match_obj), abs = FALSE)

df_matched <- match.data(match_obj)

df_matched %>%
  group_by(Dt2_math) %>%
  summarise(n = n(), mean = mean(Dt2_gpa, na.rm = FALSE), sd = sd(Dt2_gpa, na.rm = TRUE))

propensity_mod_GPA <- lm(Dt2_gpa ~ 1 + Dt2_math, 
                     data = df_matched, 
                     weights = weights)

coeftest(propensity_mod_GPA, vcov. = vcovCL, cluster = ~subclass) # cluster-robust SEs
coefci(propensity_mod_GPA, vcov. = vcovCL, cluster = ~subclass, level = 0.95) # cluster-robust CIs

propensity_mod_homeless <- glm(Nt2_homeless ~ 1 + Dt2_math, 
                         data = df_matched, 
                         family = binomial(link = "logit"),
                         weights = weights)

coeftest(propensity_mod_pass, vcov. = vcovCL, cluster = ~subclass) # cluster-robust SEs
coefci(propensity_mod_pass, vcov. = vcovCL, cluster = ~subclass, level = 0.95) # cluster-robust CIs
exp(0.349358) # odds ratio
exp(0.823362) / (1 + exp(0.823362)) # probability of passing (no intervention)
exp(0.823362 + 0.349358) / (1 + exp(0.823362 + 0.349358)) # probability of passing (intervention)

prop.table(table(df_matched$Dt2_math, df_matched$Nt2_homeless), margin = 1) * 100

# subgroup analyses with propensity score matching
d_post %>%
  group_by(Dt2_math, Rt2_per_income) %>%
  summarise(n = n(), mean = mean(Dt2_gpa, na.rm = TRUE), sd = sd(Dt2_gpa, na.rm = TRUE))

d_post %>%
  group_by(Dt2_math, Dt2_race_ML) %>%
  summarise(n = n(), mean = mean(Dt2_gpa, na.rm = TRUE), sd = sd(Dt2_gpa, na.rm = TRUE))

# graphs

## raw data
plot_means <- ggplot(data = d_post, aes(x = Dt2_math, y = Dt2_gpa)) +
  stat_summary(fun = "mean", geom = "bar", fill = "#182658") +
  stat_summary(fun.data = "mean_cl_normal", geom = "errorbar", width = 0.5, size = 1) +
  scale_x_discrete(name = "Group", labels = c("No Math", "Math")) +
  scale_y_continuous(name = "Grade", limits = c(0, 4), breaks = seq(0, 4, 0.5)) +
  labs(title = "Mean Difference in Grades", subtitle = "No Matching") +
  #theme_ML +
  theme(
    axis.title.x = element_blank()
  )

## matched data
plot_means_propensity <- ggplot(data = df_matched, aes(x = Dt2_math, y = Dt2_gpa)) +
  stat_summary(fun = "mean", geom = "bar", fill = "#182658") +
  stat_summary(fun.data = "mean_cl_normal", geom = "errorbar", width = 0.5, size = 1) +
  scale_x_discrete(name = "Group", labels = c("No Math", "Math")) +
  scale_y_continuous(name = "Grade", limits = c(0, 4), breaks = seq(0, 4, 0.5)) +
  labs(subtitle = "Propensity Score Matching") +
  #theme_ML +
  theme(
    axis.title.x = element_blank()
  )

ggarrange(plot_means, plot_means_propensity, nrow = 2)

```


### Creating a color scheme to match our ML branding and use in our graphs

``` {r include = TRUE}

# This script loads the function theme_ML.

# load libraries
library(showtext)

# load font
# font_add_google("Lora")
showtext_auto() # to work on R Studio

# load logo
logo_file_path <- "~/ML P Cen.jpg"
logo <- magick::image_read(logo_file_path)

# set font and color
font <- "Times" # Lora not working
ML_color <- "black" # font color

# create theme_ML
theme_ML <- theme(
  # font
  text = element_text(family = font),
  # grid elements
  panel.grid.major.x = element_blank(), #removes all vertical grid lines
  panel.grid.major.y = element_line(colour = "lightgray", 
                                    linewidth = 0.2,
                                    linetype = "longdash"),
  panel.grid.minor.x = element_blank(), #removes some horizontal lines
  panel.grid.minor.y = element_blank(),
  panel.grid = element_line(colour = "black"), ##### FIX (black over gray)
  panel.background = element_blank(),
  plot.title = element_text(
    family = font,
    size = 20,
    color = ML_color, 
    face = 'bold', 
    hjust = 0.5,
    vjust = 0.5
  ), 
  plot.subtitle = element_text(
    family = font,
    size = 14,
    color = ML_color
  ),
  plot.caption = element_text(
    family = font,
    size = 9,
    color = ML_color, 
    face = 'bold'
  ),
  axis.text = element_text(
    family = font,
    size = 16,
    color = "#3c3937" 
  ),
  axis.ticks.y = element_blank(),
  axis.title = element_text(
    family = font,
    size = 24,
    color = ML_color 
    # face = 'bold'
  ),
  # legend elements
  legend.key = element_blank(), # transparent legend background
  legend.background = element_rect(
    color = "black", #color of lines around legend boxes
    fill = "white", #fill of legend boxes
    linewidth = .8, #size of legend lines
    linetype = "solid"), #type of legend lines
)

```



