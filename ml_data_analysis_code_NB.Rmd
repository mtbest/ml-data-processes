---
title: "ML Data Analysis Code"
output: html_notebook
---
# ML Data Analysis Code

## Intro

This is the R Notebook for our ML Data Analysis Code. We originally worked on this in an RScript, but will now use an R Notebook for it. The data used in this file will come from a simulated dataset.

## Download packages

``` {r include = FALSE}
library(tidyverse) # for data management
library(psych) # to analyze data and descriptive statistics
library(ggplot2) # to make some nice graphs
library(pander) # to make some clean tables
library(here) # to make it easier to grab files from the folder where this one sits

```

## Load in RScript where functions are created

We don't have an RScript with functions yet

``` {r include = TRUE}

#source(__.R)

```

## Download Simulated Data

``` {r include = TRUE}

source(here(simulate-data.R))

```


## Data Analysis

### ANOVAs with Tukey HSD post-hocs

``` {r include = TRUE}

dv_gv_AOV <- aov(lm(St2_bel_bu5 ~ as.factor(Dt2_deg), data = d_post)) # BU is the dependent variable
pander(summary(dv_gv_AOV))                         # and degree is the group variable
TukeyHSD(dv_gv_AOV)

pander(summarySE(d, groupvar="Dt2_deg", measurevar="St2_bel_bu5",na.rm=TRUE),round=2)

```


### Factorial ANOVAs with other post-hoc corrections

``` {r include = TRUE}

# import libraries
library(phia)

# get descriptive statistics
describeBy(d_post$Dt2_gpa, group=list(d_post$Dt2_female, d_post$St2_bel_bu1))

# plot the data
ggplot(data=d_post, aes(x=Dt2_gpa, fill=St2_bel_bu1)) +
  geom_dotplot() + 
  facet_grid(~Dt2_female)

# build statistical model
model <- aov(Dt2_gpa ~ Dt2_female*St2_bel_bu1, data=d_post)
anova(model)

# there was a significant interaction, so we will look at simple effects
interactionMeans(model) # viewing adjusted means  
plot(interactionMeans(model)) # plotting the means to get a quick view of the results

# plot bar graph
ggplot(data=d_post, aes(y=Dt2_gpa, x=St2_bel_bu1, fill=Dt2_female)) +
  stat_summary(fun="mean", geom="bar", position="dodge") +
  stat_summary(fun.data="mean_se", geom="errorbar", position=position_dodge(.9), width=.5)

# simple effects testing
testInteractions(model, fixed="St2_bel_bu1", pairwise="Dt2_female", adjustment="none") # simple effects testing
testInteractions(model, fixed="Dt2_female", pairwise="St2_bel_bu1", adjustment="none") # notice that there is no adjustment to the p-value


```


### Correlation matrix

``` {r include = TRUE}

# Creating a function to create nice correlation matrices

cortable <- function(x){ 
  require(Hmisc) 
  x <- as.matrix(x) 
  R <- rcorr(x)$r 
  p <- rcorr(x)$P 
  ## define notions for significance levels; spacing is important.
  mystars <- ifelse(p < .001, "***", ifelse(p < .01, "** ", ifelse(p < .05, "* ", " ")))
  ## truncate the matrix that holds the correlations to two decimal
  R <- format(round(cbind(rep(-1.11, ncol(x)), R), 2))[,-1] 
  ## build a new matrix that includes the correlations with their appropriate stars 
  Rnew <- matrix(paste(R, mystars, sep=""), ncol=ncol(x)) 
  diag(Rnew) <- paste(diag(R), " ", sep="") 
  rownames(Rnew) <- colnames(x) 
  colnames(Rnew) <- paste(colnames(x), "", sep="") 
  ## remove upper triangle
  Rnew <- as.matrix(Rnew)
  Rnew[upper.tri(Rnew, diag = TRUE)] <- ""
  Rnew <- as.data.frame(Rnew) 
  ## remove last column and return the matrix (which is now a data frame)
  Rnew <- cbind(Rnew[1:length(Rnew)-1])
  return(Rnew) 
} 

# Example code for a correlation matrix

ex <- d_post %>% dplyr::select(St2_mot_a_1, St2_mot_a_2, St2_mot_a_3, St2_mot_a_4,
                     St2_mot_a_5, St2_mot_a_6, St2_mot_a_7, St2_mot_a_8,
                     St2_mot_a_9, St2_mot_a_10, St2_mot_a_11, St2_mot_b_1,
                     St2_mot_b_2, St2_mot_b_3, St2_mot_b_4, St2_mot_b_5,
                     St2_mot_b_6, St2_mot_b_7, St2_mot_b_8)

ex_corr <- cortable(ex)

pander(ex_corr,round=2,title = "Item Correlations")

```


### Creating great tables and graphs

``` {r include = TRUE}

```


### EFA

``` {r include = TRUE}

d_post$motives <- d_post %>% dplyr::select(St2_mot_a_1, St2_mot_a_2, St2_mot_a_3, St2_mot_a_4,
                     St2_mot_a_5, St2_mot_a_6, St2_mot_a_7, St2_mot_a_8,
                     St2_mot_a_9, St2_mot_a_10, St2_mot_a_11, St2_mot_b_1,
                     St2_mot_b_2, St2_mot_b_3, St2_mot_b_4, St2_mot_b_5,
                     St2_mot_b_6, St2_mot_b_7, St2_mot_b_8)

pander(fa.parallel(d_post$motives))

```


### CFA

``` {r include = TRUE}

CFA_mod1 <- 
  'F1 = ~ St2_mot_a_1 + St2_mot_a_2 + St2_mot_a_3 + St2_mot_a_4
   F2 = ~ St2_mot_a_6 + St2_mot_a_7 + St2_mot_a_8 +
          St2_mot_a_9 + St2_mot_a_10 + St2_mot_a_11
   F3 = ~ St2_mot_b_5 + St2_mot_b_6 + St2_mot_b_7 + St2_mot_b_8'

CFA1 <- cfa(model = CFA_mod1, data = d_post)

pander(summary(CFA1, fit.measures = TRUE, standardized = TRUE))
pander(inspect(CFA1, "std")$lambda)

pander(fitMeasures(CFA1, fit.measures = c("cfi", "tli", "rmsea")))
pander(standardizedSolution(CFA1) %>%
         filter(op == "=~" & lhs == "F2"))

semPaths(CFA1)

```


### Path analysis and SEM

``` {r include = TRUE}

```


### Reliability / Cronbach's alpha coefficients

``` {r include = TRUE}

d_post$scale <- d_post[c("St2_mot_a_1", "St2_mot_a_2", "St2_mot_a_3". "St2_mot_a_4")]
scale_alpha <- alpha(d$scale)
pander(scale_alpha$total)
pander(cortable(d_post$scale)) # uses correlation matrix function from above to look at
                          # inter-item correlations

```


### Linear regression

``` {r include = TRUE}

lm(Dt2_gpa ~ St2_bel1, data = d_post) # very basic linear regression equation
ggplot(data, aes(St2_bel1, Dt2_gpa)) +
  geom_point() + geom_smooth(method = "lm", se = 0)

lm(Dt2_gpa ~ St2_bel1 + factor(Nt2_pell_selfreport) + St2_bel1:factor(Nt2_pell_selfreport), data = d_post) # interaction linear regression equation
ggplot(data, aes(St2_bel1, Dt2_gpa, color = factor(Nt2_pell_selfreport))) +
  geom_point() + geom_smooth(method = "lm", se = 0)

```


### Logistic regression

``` {r include = TRUE}

glm(Nt2_couchsurf ~ St2_bel1, data, family = 'binomial') # very basic logistic regression equation

```


### Tests of baseline equivalence

``` {r include = TRUE}

```


### Multilevel models / HLMs

Given these models need context, this code below is for an analysis of student data in a university system predicting GPA. Here, we look at the random effect of institution on the outcome of GPA in tandem with belonging variables and demographic variables.

``` {r include = TRUE}

mod1 <- lmer(Dt2_gpa ~ (1|Dt2_school_RAW),data=d_post) 
mod2 <- lmer(Dt2_gpa ~ St2_bel_bu5 + St2_bel1 + St2_bel_bu5:St2_bel1 + (1|Dt2_school_RAW),data=d_post) 
mod3 <- lmer(Dt2_gpa ~ Dt2_race_ML + Dt2_female + (1|Dt2_school_RAW),data=d_post) 
mod4 <- lmer(Dt2_gpa ~ St2_bel_bu5 + St2_bel1 + St2_bel_bu5:St2_bel1 + Dt2_race_ML + Dt2_female + (1|Dt2_school_RAW), data=d_post)

htmlreg(list(mod1,mod2,mod3,mod4),
        
        # this adds a symbol for marginal significance
        stars= c(0.001, 0.01, 0.05, 0.1),
        #custom.coef.names = c("Intercept","Player GM (z)", "Coach GM (z)", 
        #                      "Player-Coach GM Interaction", "U-14","U-15","U-16/17",
        #                      "U-18/19","URM"),
        custom.model.names = c("Base Model","Belonging","Demographics","Both"),
        caption="Belonging Predicting GPA")


```


### Response surface analysis

``` {r include = TRUE}


```


### Cluster analysis

``` {r include = TRUE}

```


### Multigroup analysis (testing indirect effects in a path model for different demographic groups)

``` {r include = TRUE}

```


### Profile analysis

``` {r include = TRUE}

```


### Power analysis

``` {r include = TRUE}

```


### Bayesian predictive models

``` {r include = TRUE}

```


### Mediation/moderation analysis

``` {r include = TRUE}

```


### Propensity score matching

``` {r include = TRUE}

# propensity score matching
set.seed(123)

library(MatchIt)
library(lmtest)
library(sandwich)

match_obj <- d_post %>% # for the purpose of the exercise, we'll imagine whether they took a math class as the intervention
  filter(!is.na(Dt2_gpa)) %>%
  matchit(Dt2_math ~ Rt2_per_income + Dt2_race_ML + St2_sp_bel_bu1,
                     data = ., method = "nearest", distance = "glm",
                     ratio = 1,
                     replace = FALSE,
                     exact = ~ Rt2_per_income + Dt2_race_ML)
summary(match_obj)

plot(match_obj, type = "jitter", interactive = FALSE)
plot(summary(match_obj), abs = FALSE)

df_matched <- match.data(match_obj)

df_matched %>%
  group_by(Dt2_math) %>%
  summarise(n = n(), mean = mean(Dt2_gpa, na.rm = FALSE), sd = sd(Dt2_gpa, na.rm = TRUE))

propensity_mod_GPA <- lm(Dt2_gpa ~ 1 + Dt2_math, 
                     data = df_matched, 
                     weights = weights)

coeftest(propensity_mod_GPA, vcov. = vcovCL, cluster = ~subclass) # cluster-robust SEs
coefci(propensity_mod_GPA, vcov. = vcovCL, cluster = ~subclass, level = 0.95) # cluster-robust CIs

propensity_mod_homeless <- glm(Nt2_homeless ~ 1 + Dt2_math, 
                         data = df_matched, 
                         family = binomial(link = "logit"),
                         weights = weights)

coeftest(propensity_mod_pass, vcov. = vcovCL, cluster = ~subclass) # cluster-robust SEs
coefci(propensity_mod_pass, vcov. = vcovCL, cluster = ~subclass, level = 0.95) # cluster-robust CIs
exp(0.349358) # odds ratio
exp(0.823362) / (1 + exp(0.823362)) # probability of passing (no intervention)
exp(0.823362 + 0.349358) / (1 + exp(0.823362 + 0.349358)) # probability of passing (intervention)

prop.table(table(df_matched$Dt2_math, df_matched$Nt2_homeless), margin = 1) * 100

# subgroup analyses with propensity score matching
d_post %>%
  group_by(Dt2_math, Rt2_per_income) %>%
  summarise(n = n(), mean = mean(Dt2_gpa, na.rm = TRUE), sd = sd(Dt2_gpa, na.rm = TRUE))

d_post %>%
  group_by(Dt2_math, Dt2_race_ML) %>%
  summarise(n = n(), mean = mean(Dt2_gpa, na.rm = TRUE), sd = sd(Dt2_gpa, na.rm = TRUE))

# graphs

## raw data
plot_means <- ggplot(data = d_post, aes(x = Dt2_math, y = Dt2_gpa)) +
  stat_summary(fun = "mean", geom = "bar", fill = "#182658") +
  stat_summary(fun.data = "mean_cl_normal", geom = "errorbar", width = 0.5, size = 1) +
  scale_x_discrete(name = "Group", labels = c("No Math", "Math")) +
  scale_y_continuous(name = "Grade", limits = c(0, 4), breaks = seq(0, 4, 0.5)) +
  labs(title = "Mean Difference in Grades", subtitle = "No Matching") +
  #theme_ML +
  theme(
    axis.title.x = element_blank()
  )

## matched data
plot_means_propensity <- ggplot(data = df_matched, aes(x = Dt2_math, y = Dt2_gpa)) +
  stat_summary(fun = "mean", geom = "bar", fill = "#182658") +
  stat_summary(fun.data = "mean_cl_normal", geom = "errorbar", width = 0.5, size = 1) +
  scale_x_discrete(name = "Group", labels = c("No Math", "Math")) +
  scale_y_continuous(name = "Grade", limits = c(0, 4), breaks = seq(0, 4, 0.5)) +
  labs(subtitle = "Propensity Score Matching") +
  #theme_ML +
  theme(
    axis.title.x = element_blank()
  )

ggarrange(plot_means, plot_means_propensity, nrow = 2)

```


### Creating a color scheme to match our ML branding and use in our graphs

``` {r include = TRUE}

# This script loads the function theme_ML.

# load libraries
library(showtext)

# load font
# font_add_google("Lora")
showtext_auto() # to work on R Studio

# load logo
logo_file_path <- "~/ML P Cen.jpg"
logo <- magick::image_read(logo_file_path)

# set font and color
font <- "Times" # Lora not working
ML_color <- "black" # font color

# create theme_ML
theme_ML <- theme(
  # font
  text = element_text(family = font),
  # grid elements
  panel.grid.major.x = element_blank(), #removes all vertical grid lines
  panel.grid.major.y = element_line(colour = "lightgray", 
                                    linewidth = 0.2,
                                    linetype = "longdash"),
  panel.grid.minor.x = element_blank(), #removes some horizontal lines
  panel.grid.minor.y = element_blank(),
  panel.grid = element_line(colour = "black"), ##### FIX (black over gray)
  panel.background = element_blank(),
  plot.title = element_text(
    family = font,
    size = 20,
    color = ML_color, 
    face = 'bold', 
    hjust = 0.5,
    vjust = 0.5
  ), 
  plot.subtitle = element_text(
    family = font,
    size = 14,
    color = ML_color
  ),
  plot.caption = element_text(
    family = font,
    size = 9,
    color = ML_color, 
    face = 'bold'
  ),
  axis.text = element_text(
    family = font,
    size = 16,
    color = "#3c3937" 
  ),
  axis.ticks.y = element_blank(),
  axis.title = element_text(
    family = font,
    size = 24,
    color = ML_color 
    # face = 'bold'
  ),
  # legend elements
  legend.key = element_blank(), # transparent legend background
  legend.background = element_rect(
    color = "black", #color of lines around legend boxes
    fill = "white", #fill of legend boxes
    linewidth = .8, #size of legend lines
    linetype = "solid"), #type of legend lines
)

```



